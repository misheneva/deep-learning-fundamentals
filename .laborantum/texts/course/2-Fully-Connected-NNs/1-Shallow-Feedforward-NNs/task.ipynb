{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The autoreload extension is already loaded. To reload it, use:\n",
                        "  %reload_ext autoreload\n"
                    ]
                }
            ],
            "source": [
                "# The following lines enable automatic reloading of modules in an IPython/Jupyter environment.\n",
                "# They work exactly like the commented lines below, but avoid errors when not running in such an environment.\n",
                "# %load_ext autoreload\n",
                "# %autoreload 2\n",
                "\n",
                "try:\n",
                "    # Only defined inside IPython/Jupyter\n",
                "    get_ipython().run_line_magic(\"load_ext\", \"autoreload\")\n",
                "    get_ipython().run_line_magic(\"autoreload\", \"2\")\n",
                "except (NameError, AttributeError):\n",
                "    # Not running in IPython → just ignore\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initializing answer variable\n",
                "answer = {}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "DWr6cvb9pS3J"
            },
            "outputs": [],
            "source": [
                "# Some libs that we will use\n",
                "import torch\n",
                "import random\n",
                "import numpy as np\n",
                "import json_tricks\n",
                "import lovely_tensors as lt\n",
                "\n",
                "\n",
                "# Making tensor printouts better\n",
                "lt.monkey_patch()\n",
                "\n",
                "# Adding sources to the pythonpath\n",
                "import sys\n",
                "root_path = '../../../..'\n",
                "sys.path.append(root_path)\n",
                "\n",
                "import dotenv\n",
                "dotenv.load_dotenv(dotenv.find_dotenv(root_path + '/.env'))\n",
                "\n",
                "# Importing sources of our project\n",
                "import src as src"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 0: Prepare the environment"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For that you have to fill out the function in `src/utils/seed.py`\n",
                "\n",
                "Inside this function you should initialize the libs:\n",
                "- `numpy`\n",
                "- `random`\n",
                "- `torch`\n",
                "\n",
                "It is important for the reproducibility of your code and is always important when running experiments\n",
                "\n",
                "Note that in `torch` you have to seed both `cpu` part of the package along with `gpu` part of the package\n",
                "\n",
                "Yet another important thing to do there is to switch `gpu` to deterministic backend. Otherwise the experiments will not be fully reproducible"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [],
            "source": [
                "src.utils.seed.seed_all(0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Training a Fully Connected Feedforward Neural Network"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this exercise we will train an FCNN to classify digits into 10 classes (0, 1, 2, ..., 9).\n",
                "\n",
                "To build such network, we will use:\n",
                "- Fully Connected NN\n",
                "- Adam Optimizer\n",
                "- MNIST dataset\n",
                "- Accuracy metrics\n",
                "- Softmax final activation loss function (but we will embed it into the loss function)\n",
                "- Cross-Entropy loss\n",
                "\n",
                "But what really is important in this exercise is that we will build all the elements that we will in the future use to train all other networks. Thus, this exercise is needed to settle the basis for all our future experiments. If you will work with training neural networks, you will use all that we will touch in this notebook in different scenarios.\n",
                "\n",
                "Thus, this notebook is way closer to the real training scenarios than the previous ones."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 1: Prepare the data\n",
                "\n",
                "What you will be doing in this task is preparing your first dataloader class for one of the most popular datasets for Machine Learning -- MNIST\n",
                "\n",
                "The task is to fill out `src/datasets/mnist_simple.py` file so that you get a correctly working class of dataset (this file should open in parallel to your notebook).\n",
                "\n",
                "You have to fill out the following parts of code:\n",
                "- `__init__` function (a constructor)\n",
                "- `__len__` function (an operator of `len(object)`)\n",
                "- `__getitem__` function (that enables indexing in form of `object[index]`)\n",
                "\n",
                "You will be doing all that when you will be writing your own datasets with one exception: your classes will have significantly more complicated logics.\n",
                "\n",
                "The task here is:\n",
                "- In `__init__` get MNIST dataset from `torchvision.datasets` and initialize it. \n",
                "    Store the data in your home directory (`~/`) to avoid overloading your repo. \n",
                "    Note that you have to account for training and validation datasets that are controlled by the flag `train`\n",
                "- In `__getlen__` the task is to return the number of samples in your data. \n",
                "    It should be number of images in the dataset object\n",
                "\n",
                "- Lastly, you have to implement indexing operator `__getitem__(self, index)`\n",
                "    In this method you should:\n",
                "    - get the image\n",
                "    - get the label\n",
                "    - preprocess the image. This step contains:\n",
                "        - transform the image to a float tensor (the reason is that half is not suppoerted for CPUs)\n",
                "        - a good practice is to normalize the input data to have mean 0 and variance 1, so we should normalize it.\n",
                "            Althouth we do not know exactly the mean and the variance of the dataset, but assuming that every pixel\n",
                "            is in the range 0-255, we can assume that the mean is 127 and the variance is 127.\n",
                "            So we can approximately normalize the input by (x / 255) * 2 - 1\n",
                "            Yes, that is not an exact normalization, but haaving data within range (-1, 1) is a good approximation of normalization\n",
                "    - return the image and the label\n",
                "\n",
                "After that fill out the cell below that initializes objects of the class"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "MqGQWTDIpS3R"
            },
            "outputs": [],
            "source": [
                "import torch\n",
                "import torchvision.datasets as datasets\n",
                "from torchvision import transforms\n",
                "\n",
                "from src.datasets.mnist_simple import MNISTSimpleDataset\n",
                "\n",
                "## YOUR CODE HERE\n",
                "class MNISTSimple:\n",
                "    def __init__(self, train=True, root='~/'):\n",
                "        transform = transforms.Compose([\n",
                "            transforms.ToTensor(),\n",
                "            transforms.Normalize((0.5,), (0.5,))  \n",
                "        ])\n",
                "        self.dataset = datasets.MNIST(\n",
                "            root=root,\n",
                "            train=train,\n",
                "            download=True,\n",
                "            transform=transform\n",
                "        )\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.dataset)\n",
                "    \n",
                "    def __getitem__(self, index):\n",
                "        image, label = self.dataset[index]\n",
                "        image = image.float().squeeze(0)\n",
                "        label = torch.tensor(label, dtype=torch.int64)\n",
                "        return {\n",
                "            'image': image,\n",
                "            'label': label\n",
                "        }\n",
                "\n",
                "# MNIST_train = MNISTSimple(train=True)\n",
                "# MNIST_valid = MNISTSimple(train=False)\n",
                "\n",
                "MNIST_train = MNISTSimpleDataset(train=True)\n",
                "MNIST_valid = MNISTSimpleDataset(train=False)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Check that the data is prepared:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "vv_Lz7PYpS3U"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'image': tensor[28, 28] n=784 (3.1Kb) x∈[-1.000, 1.000] μ=-0.725 σ=0.625, 'label': tensor i64 5}\n",
                        "tensor[28, 28] n=784 (3.1Kb) x∈[-1.000, 1.000] μ=-0.725 σ=0.625\n",
                        "tensor[28, 28] n=784 (3.1Kb) x∈[-1.000, 1.000] μ=-0.815 σ=0.518\n"
                    ]
                }
            ],
            "source": [
                "train_sample = MNIST_train[0]\n",
                "valid_sample = MNIST_valid[0]\n",
                "\n",
                "X_train = train_sample['image']\n",
                "X_valid = valid_sample['image']\n",
                "y_train = train_sample['label']\n",
                "y_valid = valid_sample['label']\n",
                "\n",
                "print(MNIST_train[0])\n",
                "print(X_train)\n",
                "print(X_valid)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 35
                },
                "colab_type": "code",
                "id": "hMhsAedlrQF5",
                "outputId": "ae08bd21-79ff-48da-9886-48996a178110"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "torch.float32 torch.float32 torch.int64 torch.int64\n",
                        "torch.Size([28, 28]) torch.Size([28, 28]) torch.Size([]) torch.Size([])\n",
                        "tensor[28, 28] n=784 (3.1Kb) x∈[-1.000, 1.000] μ=-0.725 σ=0.625\n",
                        "tensor[28, 28] n=784 (3.1Kb) x∈[-1.000, 1.000] μ=-0.815 σ=0.518\n",
                        "tensor i64 5\n",
                        "tensor i64 7\n"
                    ]
                }
            ],
            "source": [
                "## This checks are for dataset verification\n",
                "answer['X_train.dtype'] = str(X_train.dtype)\n",
                "answer['y_train.dtype'] = str(y_train.dtype)\n",
                "answer['X_valid.dtype'] = str(X_valid.dtype)\n",
                "answer['y_valid.dtype'] = str(y_valid.dtype)\n",
                "answer['X_train.shape'] = X_train.shape\n",
                "answer['X_valid.shape'] = X_valid.shape\n",
                "answer['y_train.shape'] = y_train.shape\n",
                "answer['y_valid.shape'] = y_valid.shape\n",
                "answer['X_train.mean'] = float(X_train.mean())\n",
                "answer['y_train.mean'] = float(y_train.float().mean())\n",
                "answer['X_valid.mean'] = float(X_valid.mean())\n",
                "answer['y_valid.mean'] = float(y_valid.float().mean())\n",
                "\n",
                "print(X_train.dtype, X_valid.dtype, y_train.dtype, y_valid.dtype)\n",
                "print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)\n",
                "\n",
                "print(X_train)\n",
                "print(X_valid)\n",
                "print(y_train)\n",
                "print(y_valid)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Neural networks are usually trained in float values. Usually in `float32` or `float16`. In this exercise we will use `float32` precision.\n",
                "\n",
                "Convert your data to `float` type"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let us visualize the data that we have"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {
                "colab": {
                    "base_uri": "https://localhost:8080/",
                    "height": 365
                },
                "colab_type": "code",
                "id": "Z1tFXMwJpS3e",
                "outputId": "e7c2778b-d6f5-4718-ea28-fc8544f0416c"
            },
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor i64 5\n"
                    ]
                }
            ],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "plt.imshow(X_train.squeeze(0))  #\n",
                "plt.show()\n",
                "print(y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 2: Build the code for the network"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "It is time to create our neural network (edit the file `src/models/feedforward/simple_fcnn.py`, should be open automatically with this chapter).\n",
                "\n",
                "In pytorch to enable all the magic for training, people enherit their models from `torch.nn.Module`.\n",
                "\n",
                "This enables many utilities that will be used in the future.\n",
                "\n",
                "The main two methods that we have to fill are:\n",
                "- `__init__` method that creates all modules of Neural Network\n",
                "    NOTE: you should also intialize the parent class's instance(`torch.nn.Module` by calling `super().__init__()`)\n",
                "- `__call__` method that is used to calculate preditions\n",
                "\n",
                "\n",
                "We will create a network for quite a general case of Fully-Connected Neural Network\n",
                "\n",
                "Here is the network that you should create:\n",
                "- it should have the structure:\n",
                "    - `network`:\n",
                "        - `Linear channels[0] -> channels[1] -> activation`\n",
                "        - `Linear channels[1] -> channels[2] -> activation`\n",
                "        - and so on\n",
                "    - `classifier`:\n",
                "        - `Linear channels[n] -> n_classes`\n",
                "- the signals that you create should traverse the initialized modules according to the order above\n",
                "\n",
                "That is the simple n-layer fully connected network.\n",
                "\n",
                "The network should have two parts:\n",
                "- `backbone` (containing all the layers except for the last linear layer)\n",
                "- `classifier` (containing only the last layer)\n",
                "\n",
                "We like to isolate the classifier separately because it is a very special layer of the network.\n",
                "\n",
                "It also is a very good practice to wrap the modules where one block is executed after another\n",
                "into a `torch.nn.Sequential`.\n",
                "\n",
                "Note that in theory, we should use a SoftMax activation in the end. \n",
                "But in our case, this activation will be joined with the loss function due to mathematical reasons."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let us check that your network actually works"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[[ 47.534428    36.74655     25.958658    15.17077      4.3828864\n",
                        "   -6.40499    -17.192877   -27.980759   -38.76862    -49.55651   ]\n",
                        " [ 34.73718     26.70789     18.678589    10.649306     2.620015\n",
                        "   -5.409278   -13.438574   -21.467875   -29.497145   -37.526432  ]\n",
                        " [-26.24253    -20.85863    -15.474689   -10.090753    -4.7068243\n",
                        "    0.67710316   6.0610332   11.444956    16.828873    22.21284   ]\n",
                        " [-48.49079    -38.161205   -27.831556   -17.50195     -7.1723228\n",
                        "    3.1572921   13.486914    23.816517    34.146168    44.4758    ]\n",
                        " [ 37.54093     28.97958     20.418238    11.856902     3.295556\n",
                        "   -5.2657924  -13.827126   -22.388475   -30.949816   -39.511166  ]\n",
                        " [ 13.687252    10.5518875    7.4165215    4.2811456    1.1457713\n",
                        "   -1.9895967   -5.1249633   -8.260348   -11.3956995  -14.531096  ]\n",
                        " [ -3.8816497   -3.2775245   -2.6733956   -2.0692725   -1.4651417\n",
                        "   -0.8610102   -0.25688112   0.34724817   0.9513795    1.5555007 ]\n",
                        " [ 11.438421     8.716123     5.9938135    3.271515     0.54921126\n",
                        "   -2.1730912   -4.895398    -7.617699   -10.34       -13.062321  ]\n",
                        " [ 18.083706    13.631853     9.180021     4.728181     0.27634332\n",
                        "   -4.1754923   -8.627324   -13.079159   -17.53101    -21.982828  ]\n",
                        " [  6.346822     4.472488     2.5980935    0.72372353  -1.1506417\n",
                        "   -3.02501     -4.8993764   -6.7737455   -8.648121   -10.522477  ]]\n"
                    ]
                }
            ],
            "source": [
                "simple_network = src.models.feedforward.simple_fcnn.SimpleFCNN([28 * 28], n_classes=10)\n",
                "\n",
                "src.utils.deterministic_init(simple_network)\n",
                "\n",
                "check_input = {'image': torch.randn(10, 28 * 28)}\n",
                "check_output = simple_network(check_input['image'])\n",
                "\n",
                "answer['check_result'] = src.utils.detach_copy(check_output)\n",
                "\n",
                "print(answer['check_result'] )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 3: Create loss function and optimizer\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "All right, so now we have prepared the dataset and the network.\n",
                "We are still missing several other modules that are important for model training:\n",
                "- optimizer\n",
                "- loss function\n",
                "- metrics\n",
                "\n",
                "To train this network we will use the following components:\n",
                "- `AdamW` as an optimizer (`torch.optim.AdamW`) with standard parameters and `lr` equal to $3 \\cdot 10^{-4}$\n",
                "- `CE` as a loss function (`torch.nn.CrossEntropy`). Note that this loss function already includes `SoftMax` activation function (and we should remember that this activation is compatible with this loss function). We could code it ourselves, it is not hard, but the standard implementation from pytorch is numerically more stable\n",
                "- `accuracy` as a metrics (we will use the one coded in `torchmetrics`)\n",
                "\n",
                "There are also several training tricks that are very nice to use.\n",
                "As such, we will use the learning rate scheduler `torch.optim.schedulers.ReduceLROnPlateu`\n",
                "\n",
                "Let us prepare what we need now!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "00_2j2igpS3o"
            },
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
                "import torchmetrics\n",
                "\n",
                "loss = nn.CrossEntropyLoss()\n",
                "optimizer = optim.AdamW(simple_network.parameters(), lr=3e-4) # \n",
                "scheduler = ReduceLROnPlateau(\n",
                "    optimizer, \n",
                "    mode='min',           \n",
                "    factor=0.1,           \n",
                "    patience=5,           \n",
                "    # verbose=True,         \n",
                "    min_lr=1e-6 #1e-4 # \n",
                ")\n",
                "metrics = torchmetrics.Accuracy(task='multiclass', num_classes=10)\n",
                "## YOUR CODE HERE\n",
                "# X_train=np.reshape(X_train, (X_train.shape[0],28,28,1))\n",
                "# X_val=np.reshape(X_val, (X_val.shape[0],28,28,1))\n",
                "\n",
                "# X_train_flat = MNIST_train.reshape(784)\n",
                "# X_valid_flat = MNIST_valid.reshape(784)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CrossEntropyLoss()\n",
                        "AdamW (\n",
                        "Parameter Group 0\n",
                        "    amsgrad: False\n",
                        "    betas: (0.9, 0.999)\n",
                        "    capturable: False\n",
                        "    decoupled_weight_decay: True\n",
                        "    differentiable: False\n",
                        "    eps: 1e-08\n",
                        "    foreach: None\n",
                        "    fused: None\n",
                        "    lr: 0.0003\n",
                        "    maximize: False\n",
                        "    weight_decay: 0.01\n",
                        ")\n",
                        "<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0xffff61c0d350>\n",
                        "MulticlassAccuracy()\n"
                    ]
                }
            ],
            "source": [
                "answer['loss'] = str(loss)\n",
                "answer['optimizer'] = str(optimizer)\n",
                "answer['scheduler'] = str(scheduler)\n",
                "answer['metrics'] = str(metrics)\n",
                "\n",
                "print(loss)\n",
                "print(optimizer)\n",
                "print(scheduler)\n",
                "print(metrics)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 4: Create DataLoaders"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now it is time to start the training process\n",
                "\n",
                "Firstly, we need to turn our datasets into dataloaders (dataloaders know, how to create batches of data and takes care of shuffling them)\n",
                "\n",
                "You should use the class `torch.utils.data.DataLoader` to create training and validation dataloaders.\n",
                "\n",
                "What is important here is that you should shuffle the data for training, while you should not do it during validation.\n",
                "\n",
                "Also the last batch of the training dataloader may be deficient and should be dropped (there is a special option in the DataLoader class dedicated for that).\n",
                "\n",
                "Use batch size that is given below"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {
                "colab": {},
                "colab_type": "code",
                "id": "wZtqiGvfpS3r"
            },
            "outputs": [],
            "source": [
                "from tqdm import trange, tqdm\n",
                "# import neptune\n",
                "import os\n",
                "\n",
                "batch_size = 32 # 16 # 32 # 128 # 512 \n",
                "\n",
                "train_dl = torch.utils.data.DataLoader(\n",
                "    MNIST_train, \n",
                "    batch_size=batch_size, \n",
                "    num_workers=8,\n",
                "    shuffle=True,\n",
                "    pin_memory=True, \n",
                "    persistent_workers=True,\n",
                "    drop_last=True)\n",
                "\n",
                "valid_dl = torch.utils.data.DataLoader(\n",
                "    MNIST_valid, \n",
                "    num_workers=8,\n",
                "    batch_size=batch_size, \n",
                "    pin_memory=True, \n",
                "    persistent_workers=True,\n",
                "    shuffle=False)\n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 5: Create training loop"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Firstly, we will use a service that allows to share the training reports. I strongly recommend using mlflow for your experiments, but for the sake of being able to share the results, we will use [neptune.ai](https://neptune.ai/)\n",
                "\n",
                "Create an account there, create your first experiment (and name it something like `MNIST FCNN`)\n",
                "\n",
                "Then create run with `neptune.ai` in your code.\n",
                "\n",
                "After that you will be able to see on that website the flow of your experiment.\n",
                "\n",
                "Then it is time to create the training cycle.\n",
                "\n",
                "Training cycles usually are custom for every network, because of that we will not create one for all the cases.\n",
                "\n",
                "Training cycles run in epochs each containing 2 stages:\n",
                "- training\n",
                "- validation\n",
                "\n",
                "Here is what you should do in the training stage:\n",
                "1. extract training batch from training dataloader\n",
                "2. switch the network to training state (`model.train()`)(will be important for batchnorms and some other modules)\n",
                "2. generate predictions from the training inputs using the model (`model(inputs)`)\n",
                "3. calculate the value of the loss that compares the predictions to the targets\n",
                "4. perform backpropagation (`loss_val.backward()`)\n",
                "5. make optimization step  with optimizer (`optimizer.step()`)\n",
                "6. reset optimizer's gradients (`optimizer.zero_grad()`)\n",
                "7. switch the network to validation state (`model.eval()`)\n",
                "8. evaluate training the accuracy of your model and update metrics that keep track of accuracy and loss (averaged throughout the training step)\n",
                "\n",
                "This should be done in iterations for all training batches that come out from `train_dl`\n",
                "\n",
                "Note that it is extremely important to do `detach` when you memorize accuracy and loss values so that after each iteration RAM is freed automatically by pytorch (because in case we plan to perform backprop, all the intermediate values are needed, and cannot be freed).\n",
                "\n",
                "Once in a while, if you experience RAM leakage, you should make sure that you detach metrics and loss values that you memorize. In case that does not help, delete all the variables manually and after that call pythons's garbage collector (`gc.collect()`). This will help pytorch with cleaning RAM.\n",
                "\n",
                "If you do not want to think about detaching and other aspects of graph backpropagation in some part of your code, you may use `torch.no_grad()` context. Exactly that statement we will use during validation stage of the cycle. This context also can be used as a decorator of a function that does not require gradient propagation.\n",
                "\n",
                "Now it is time to do validation:\n",
                "- make prediction for validation data\n",
                "- calculate accuracy for the predictions for both sets\n",
                "- calculate loss function for the predictions for both sets\n",
                "\n",
                "Note that the code should look very similarly to training cycle. The only difference is that this time we do not perform backpropagation and optimizer step.\n",
                "\n",
                "By the end of each epoch, submit the report about accuracies that you gotten and loss values to neptune.ai (run['losses/loss_value/train'].log(train_loss_value))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "device(type='cpu')"
                        ]
                    },
                    "execution_count": 57,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "device"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.environ[\"NEPTUNE_API_TOKEN\"] = \"12345\"\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:04<00:00, 423.32it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 4.43s, Avg batch time: 0.0017s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:00<00:00, 425.95it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "134.9890078489861\n",
                        "0.4074000120162964\n",
                        "2 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:04<00:00, 396.83it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 4.73s, Avg batch time: 0.0019s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:00<00:00, 612.16it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "12.966227162920383\n",
                        "0.5229499936103821\n",
                        "3 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:04<00:00, 428.45it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 4.38s, Avg batch time: 0.0018s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:00<00:00, 556.12it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "3.6388033664845794\n",
                        "0.6049000024795532\n",
                        "4 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:04<00:00, 440.66it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 4.26s, Avg batch time: 0.0017s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:00<00:00, 592.97it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "1.9996295775485715\n",
                        "0.6604250073432922\n",
                        "5 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:04<00:00, 440.77it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 4.25s, Avg batch time: 0.0017s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:00<00:00, 567.24it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "1.2279627696377984\n",
                        "0.7009400129318237\n",
                        "[134.9890078489861, 12.966227162920383, 3.6388033664845794, 1.9996295775485715, 1.2279627696377984]\n",
                        "[0.4074000120162964, 0.5229499936103821, 0.6049000024795532, 0.6604250073432922, 0.7009400129318237]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "import gc\n",
                "import time\n",
                "\n",
                "n_epochs = 5\n",
                "\n",
                "def train_model(model, n_epochs, train_dl, valid_dl, loss, optimizer, scheduler=None):\n",
                "    train_loss_history = []\n",
                "    train_acc_history = []\n",
                "    valid_loss_history = []\n",
                "    valid_acc_history = []\n",
                "\n",
                "    ## YOU SHOULD ADD THE nepune.ai TOKEN BEFORE RUNNING THE TRAINING\n",
                "    # run = neptune.init_run(\n",
                "    #     project=\"osa/osa_mnist_fcnn\",  \n",
                "    #     api_token=neptune_token,  \n",
                "    #     name=\"MNIST FCNN Training\",\n",
                "    #     tags=[\"MNIST\", \"FCNN\", \"pytorch\"]\n",
                "    # )\n",
                "\n",
                "    # run[\"parameters/learning_rate\"] = optimizer.param_groups[0]['lr']\n",
                "    # run[\"parameters/epochs\"] = n_epochs\n",
                "    # run[\"parameters/batch_size\"] = train_dl.batch_size\n",
                "    # run[\"parameters/optimizer\"] = type(optimizer).__name__\n",
                "    # run[\"parameters/loss_function\"] = type(loss).__name__\n",
                "\n",
                "     # Инициализация метрик accuracy\n",
                "    train_accuracy_metric = torchmetrics.Accuracy(task='multiclass', num_classes=10) # metrics\n",
                "    valid_accuracy_metric = torchmetrics.Accuracy(task='multiclass', num_classes=10) # metrics\n",
                "\n",
                "    # Перенос метрик на GPU если доступно\n",
                "    if torch.cuda.is_available():\n",
                "        train_accuracy_metric = train_accuracy_metric.cuda()\n",
                "        valid_accuracy_metric = valid_accuracy_metric.cuda()\n",
                "        model = model.cuda()\n",
                "\n",
                "    for epoch in range(n_epochs):\n",
                "        epoch_start = time.time()\n",
                "\n",
                "        train_loss = {'enumerator': 0.0, 'denominator': 1.0e-8}\n",
                "        train_acc = {'enumerator': 0.0, 'denominator': 1.0e-8}\n",
                "        valid_loss = {'enumerator': 0.0, 'denominator': 1.0e-8}\n",
                "        valid_acc = {'enumerator': 0.0, 'denominator': 1.0e-8}\n",
                "\n",
                "        print(epoch + 1, '/', n_epochs)\n",
                "        \n",
                "        batch_times = []\n",
                "\n",
                "        for batch in tqdm(train_dl):\n",
                "            ## YOUR TRAINING CODE HERE\n",
                "            batch_start = time.time()\n",
                "\n",
                "            inputs = batch['image']\n",
                "            targets = batch['label']\n",
                "\n",
                "            if torch.cuda.is_available():\n",
                "                inputs = inputs.cuda()\n",
                "                targets = targets.cuda()\n",
                "\n",
                "            optimizer.zero_grad()\n",
                "            outputs = model(inputs)\n",
                "            \n",
                "            loss_value = loss(outputs, targets)\n",
                "            \n",
                "            loss_value.backward()\n",
                "            optimizer.step()\n",
                "            \n",
                "            train_loss['enumerator'] += loss_value.item() * inputs.size(0)\n",
                "            train_loss['denominator'] += inputs.size(0)\n",
                "            \n",
                "            train_accuracy_metric.update(outputs, targets)\n",
                "            \n",
                "            # Очистка памяти\n",
                "            # del inputs, targets, outputs,\n",
                "            # gc.collect()\n",
                "\n",
                "            batch_time = time.time() - batch_start\n",
                "            batch_times.append(batch_time)\n",
                "\n",
                "        epoch_time = time.time() - epoch_start\n",
                "        avg_batch_time = sum(batch_times) / len(batch_times)\n",
                "        print(f\"Epoch time: {epoch_time:.2f}s, Avg batch time: {avg_batch_time:.4f}s\")\n",
                "        # print(f\"Data loading time: {data_loading_time:.2f}s\")\n",
                "        \n",
                "        model.eval()\n",
                "        with torch.no_grad():\n",
                "            for valid_batch in tqdm(valid_dl):\n",
                "                ## YOUR EVALUATION CODE HERE\n",
                "                inputs = valid_batch['image']\n",
                "                targets = valid_batch['label']\n",
                "                \n",
                "                if torch.cuda.is_available():\n",
                "                    inputs = inputs.cuda()\n",
                "                    targets = targets.cuda()\n",
                "                \n",
                "                outputs = model(inputs)\n",
                "                loss_value = loss(outputs, targets)\n",
                "                \n",
                "                valid_loss['enumerator'] += loss_value.item() * inputs.size(0)\n",
                "                valid_loss['denominator'] += inputs.size(0)\n",
                "                \n",
                "                valid_accuracy_metric.update(outputs, targets)\n",
                "                \n",
                "                # del inputs, targets, outputs\n",
                "                # gc.collect()\n",
                "\n",
                "            print(valid_acc['enumerator'], valid_acc['denominator'], '<- Validation accuracy debug')    \n",
                "\n",
                "            finalized_train_loss = train_loss['enumerator'] / train_loss['denominator']\n",
                "            finalized_train_accuracy = train_accuracy_metric.compute().item() # train_acc['enumerator'] / train_acc['denominator']\n",
                "            \n",
                "            finalized_valid_loss = valid_loss['enumerator'] / valid_loss['denominator']\n",
                "            finalized_valid_accuracy = valid_accuracy_metric.compute().item() # valid_acc['enumerator'] / valid_acc['denominator']\n",
                "\n",
                "            # Logging the progress to neptune\n",
                "            # run[\"metrics/train_loss\"].log(finalized_train_loss)\n",
                "            # run[\"metrics/train_accuracy\"].log(finalized_train_accuracy)\n",
                "            # run[\"metrics/valid_loss\"].log(finalized_valid_loss)\n",
                "            # run[\"metrics/valid_accuracy\"].log(finalized_valid_accuracy)\n",
                "            # run[\"metrics/learning_rate\"].log(optimizer.param_groups[0]['lr'])\n",
                "\n",
                "            if scheduler is not None:\n",
                "                scheduler.step(finalized_valid_loss)\n",
                "                # run[\"metrics/learning_rate\"].log(optimizer.param_groups[0]['lr'])\n",
                "\n",
                "            train_loss_history.append(finalized_train_loss)\n",
                "            train_acc_history.append(finalized_train_accuracy)\n",
                "            valid_loss_history.append(finalized_valid_loss)\n",
                "            valid_acc_history.append(finalized_valid_accuracy)\n",
                "\n",
                "            print(finalized_valid_loss)\n",
                "            print(finalized_valid_accuracy)\n",
                "\n",
                "    # run.stop()\n",
                "    return train_loss_history, train_acc_history, valid_loss_history, valid_acc_history\n",
                "\n",
                "\n",
                "with src.utils.safecatch():\n",
                "    train_loss_history, train_acc_history, valid_loss_history, valid_acc_history = train_model(simple_network, n_epochs, train_dl, valid_dl, loss, optimizer, scheduler)\n",
                "\n",
                "print(valid_loss_history)\n",
                "print(valid_acc_history)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'{\"X_train.dtype\": \"torch.float32\", \"y_train.dtype\": \"torch.int64\", \"X_valid.dtype\": \"torch.float32\", \"y_valid.dtype\": \"torch.int64\", \"X_train.shape\": [28, 28], \"X_valid.shape\": [28, 28], \"y_train.shape\": [], \"y_valid.shape\": [], \"X_train.mean\": -0.724639892578125, \"y_train.mean\": 5.0, \"X_valid.mean\": -0.815386176109314, \"y_valid.mean\": 7.0, \"check_result\": {\"__ndarray__\": [[47.534427642822266, 36.746551513671875, 25.95865821838379, 15.170769691467285, 4.3828864097595215, -6.404990196228027, -17.1928768157959, -27.980758666992188, -38.768619537353516, -49.55651092529297], [34.737178802490234, 26.707889556884766, 18.6785888671875, 10.649306297302246, 2.6200149059295654, -5.40927791595459, -13.438573837280273, -21.46787452697754, -29.49714469909668, -37.526432037353516], [-26.242530822753906, -20.85862922668457, -15.474688529968262, -10.090752601623535, -4.70682430267334, 0.6771031618118286, 6.061033248901367, 11.444955825805664, 16.828872680664062, 22.212839126586914], [-48.49079132080078, -38.16120529174805, -27.83155632019043, -17.501949310302734, -7.172322750091553, 3.157292127609253, 13.486913681030273, 23.816516876220703, 34.14616775512695, 44.475799560546875], [37.540931701660156, 28.97957992553711, 20.418237686157227, 11.856902122497559, 3.29555606842041, -5.265792369842529, -13.827125549316406, -22.38847541809082, -30.94981575012207, -39.511165618896484], [13.687252044677734, 10.551887512207031, 7.4165215492248535, 4.2811455726623535, 1.1457712650299072, -1.9895967245101929, -5.124963283538818, -8.260348320007324, -11.395699501037598, -14.531096458435059], [-3.8816497325897217, -3.277524471282959, -2.6733956336975098, -2.069272518157959, -1.4651416540145874, -0.8610101938247681, -0.25688111782073975, 0.3472481667995453, 0.9513794779777527, 1.5555007457733154], [11.438421249389648, 8.7161226272583, 5.993813514709473, 3.271514892578125, 0.5492112636566162, -2.173091173171997, -4.895398139953613, -7.617699146270752, -10.34000015258789, -13.062320709228516], [18.08370590209961, 13.631853103637695, 9.180021286010742, 4.728180885314941, 0.27634331583976746, -4.175492286682129, -8.627324104309082, -13.079158782958984, -17.531009674072266, -21.98282814025879], [6.3468217849731445, 4.472487926483154, 2.5980935096740723, 0.7237235307693481, -1.150641679763794, -3.025010108947754, -4.899376392364502, -6.773745536804199, -8.648120880126953, -10.522477149963379]], \"dtype\": \"float32\", \"shape\": [10, 10], \"Corder\": true}, \"loss\": \"CrossEntropyLoss()\", \"optimizer\": \"AdamW (\\\\nParameter Group 0\\\\n    amsgrad: False\\\\n    betas: (0.9, 0.999)\\\\n    capturable: False\\\\n    decoupled_weight_decay: True\\\\n    differentiable: False\\\\n    eps: 1e-08\\\\n    foreach: None\\\\n    fused: None\\\\n    lr: 0.0003\\\\n    maximize: False\\\\n    weight_decay: 0.01\\\\n)\", \"scheduler\": \"<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0xffff61c0d350>\", \"metrics\": \"MulticlassAccuracy()\", \"train_loss_history\": [296.3329828897618, 59.097778972615885, 6.119415641728017, 2.9456201002046525, 1.7064953548657038], \"valid_loss_history\": [134.9890078489861, 12.966227162920383, 3.6388033664845794, 1.9996295775485715, 1.2279627696377984], \"train_acc_history\": [0.25218334794044495, 0.3794916570186615, 0.4897777736186981, 0.5649124979972839, 0.6188966631889343], \"valid_ann_history\": [0.4074000120162964, 0.5229499936103821, 0.6049000024795532, 0.6604250073432922, 0.7009400129318237]}'"
                        ]
                    },
                    "execution_count": 60,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "answer['train_loss_history'] = train_loss_history\n",
                "answer['valid_loss_history'] = valid_loss_history\n",
                "answer['train_acc_history'] = train_acc_history\n",
                "answer['valid_ann_history'] = valid_acc_history\n",
                "\n",
                "json_tricks.dump(answer, '.answer.json')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 7. Experiment time!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "It is the time for fun now!\n",
                "\n",
                "We have created everything that is needed for the network to train.\n",
                "\n",
                "Let us train some networks and visualize, what they see.\n",
                "\n",
                "With the code that you have created, make:\n",
                "- 1-layer FCNN (yes, simple Multiclass Logistic Regression)\n",
                "- 2-layer FCNN\n",
                "- 3-layer FCNN \n",
                "\n",
                "Train every of these networks for 100 epochs\n",
                "\n",
                "Check, what are the patterns that they learn\n",
                "\n",
                "To check the patterns, you have to take the weights of the first layer of the network, reshape them and plot."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/1875 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:05<00:00, 373.09it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 5.03s, Avg batch time: 0.0021s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:00<00:00, 496.45it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "0.32138731605676457\n",
                        "0.9021000266075134\n",
                        "2 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:05<00:00, 317.07it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 5.92s, Avg batch time: 0.0025s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:00<00:00, 485.36it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "0.29645564182669076\n",
                        "0.909250020980835\n",
                        "3 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:04<00:00, 379.43it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 4.94s, Avg batch time: 0.0020s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:00<00:00, 629.32it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "0.30443872104554726\n",
                        "0.9107666611671448\n",
                        "4 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:04<00:00, 416.19it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 4.51s, Avg batch time: 0.0018s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:00<00:00, 495.97it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "0.3018479737547001\n",
                        "0.911424994468689\n",
                        "5 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:05<00:00, 352.24it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 5.32s, Avg batch time: 0.0022s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:01<00:00, 239.63it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "0.30100148967176377\n",
                        "0.9123200178146362\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "one_layer_fcnn = src.models.feedforward.simple_fcnn.SimpleFCNN(\n",
                "    [28 * 28], \n",
                "    n_classes=10,\n",
                "    activation=torch.nn.LeakyReLU)\n",
                "\n",
                "## YOUR CODE HERE\n",
                "n_epochs = 5 # 100\n",
                "\n",
                "one_layer_optimizer = torch.optim.AdamW(one_layer_fcnn.parameters(), lr=1.0e-3)\n",
                "# one_layer_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(one_layer_optimizer, patience=5)\n",
                "# train_model(one_layer_fcnn, n_epochs, train_dl, valid_dl, loss, one_layer_optimizer)\n",
                "## YOUR CODE HERE\n",
                "train_loss_history_1, train_acc_history_1, valid_loss_history_1, valid_acc_history_1 = train_model(\n",
                "    one_layer_fcnn, n_epochs, train_dl, valid_dl, loss, one_layer_optimizer #, one_layer_scheduler\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<matplotlib.image.AxesImage at 0xffff619b9050>"
                        ]
                    },
                    "execution_count": 62,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "W = one_layer_fcnn.classifier.weight\n",
                "W = W.reshape(10, 28, 28)\n",
                "plt.imshow(W[0].detach())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:14<00:00, 129.85it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 14.44s, Avg batch time: 0.0068s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:00<00:00, 431.82it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "0.202936581016874\n",
                        "0.9405999779701233\n",
                        "2 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:09<00:00, 191.11it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 9.81s, Avg batch time: 0.0046s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:00<00:00, 430.72it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "0.1541485630052485\n",
                        "0.9465500116348267\n",
                        "3 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:09<00:00, 203.73it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 9.20s, Avg batch time: 0.0043s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:00<00:00, 391.96it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "0.1552156676149306\n",
                        "0.9488999843597412\n",
                        "4 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:09<00:00, 197.63it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 9.49s, Avg batch time: 0.0044s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:00<00:00, 406.70it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "0.12798533438543097\n",
                        "0.952049970626831\n",
                        "5 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:10<00:00, 185.78it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 10.09s, Avg batch time: 0.0047s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:00<00:00, 416.63it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "0.10675927534996099\n",
                        "0.95524001121521\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "## YOUR CODE HERE\n",
                "two_layer_fcnn = src.models.feedforward.simple_fcnn.SimpleFCNN(\n",
                "    [28 * 28, 128],  # 784 -> 128 -> 10\n",
                "    n_classes=10,\n",
                "    activation=nn.LeakyReLU\n",
                ")\n",
                "\n",
                "two_layer_optimizer = torch.optim.AdamW(two_layer_fcnn.parameters(), lr=1.0e-3)\n",
                "# two_layer_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(two_layer_optimizer, patience=5)\n",
                "\n",
                "train_loss_history_2, train_acc_history_2, valid_loss_history_2, valid_acc_history_2 = train_model(\n",
                "    two_layer_fcnn, n_epochs, train_dl, valid_dl, loss, two_layer_optimizer #, two_layer_scheduler\n",
                ")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<matplotlib.image.AxesImage at 0xffff61763910>"
                        ]
                    },
                    "execution_count": 64,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# W2 = two_layer_fcnn.classifier.weight\n",
                "W2 = list(two_layer_fcnn.parameters())[0]\n",
                "W2 = W2.reshape(128, 28, 28)\n",
                "plt.imshow(W2[0].detach())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "1 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/1875 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:12<00:00, 151.01it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 12.42s, Avg batch time: 0.0059s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:01<00:00, 262.09it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "0.1585771986564898\n",
                        "0.9509000182151794\n",
                        "2 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:08<00:00, 217.08it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 8.64s, Avg batch time: 0.0039s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:00<00:00, 411.60it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "0.12923039109004775\n",
                        "0.9556499719619751\n",
                        "3 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:07<00:00, 256.89it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 7.30s, Avg batch time: 0.0033s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:01<00:00, 272.32it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "0.10718776322504031\n",
                        "0.9595666527748108\n",
                        "4 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:09<00:00, 206.98it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 9.06s, Avg batch time: 0.0042s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:01<00:00, 289.82it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "0.10509430737463957\n",
                        "0.9615749716758728\n",
                        "5 / 5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 1875/1875 [00:08<00:00, 212.42it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch time: 8.83s, Avg batch time: 0.0041s\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 313/313 [00:00<00:00, 358.97it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0 1e-08 <- Validation accuracy debug\n",
                        "0.09639289657832961\n",
                        "0.9633200168609619\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "three_layer_fcnn = src.models.feedforward.simple_fcnn.SimpleFCNN(\n",
                "    [28 * 28, 256, 128],  # 784 -> 256 -> 128 -> 10\n",
                "    n_classes=10,\n",
                "    activation=nn.LeakyReLU\n",
                ")\n",
                "\n",
                "three_layer_optimizer = torch.optim.AdamW(three_layer_fcnn.parameters(), lr=1.0e-3)\n",
                "# three_layer_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(three_layer_optimizer, patience=5)\n",
                "\n",
                "train_loss_history_3, train_acc_history_3, valid_loss_history_3, valid_acc_history_3 = train_model(\n",
                "    three_layer_fcnn, n_epochs, train_dl, valid_dl, loss, three_layer_optimizer #, three_layer_scheduler\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "<matplotlib.image.AxesImage at 0xffff616c9690>"
                        ]
                    },
                    "execution_count": 66,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# W3 = three_layer_fcnn.classifier.weight\n",
                "W3 = list(three_layer_fcnn.parameters())[0]\n",
                "W3 = W3.reshape(256, 28, 28)\n",
                "plt.imshow(W3[0].detach())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Time to think\n",
                "\n",
                "What converges faster\n",
                "- 1-layer NN (Logistic Regression)\n",
                "- 2-layer NN\n",
                "- 3-layer NN\n",
                "\n",
                "Maybe you want to train a deeper network? Say, with 10 layers?\n",
                "\n",
                "What do the patterns from 1-layer NN resemble? Should they?\n",
                "What do the patterns from 2-layer and 3-layer NN resemble? Should they?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 8. More experiments!\n",
                "\n",
                "Try to train the networks created above with different actiavtion functions (Concentrate on 2-Layer NN):\n",
                "- Sigmoid\n",
                "- Tanh\n",
                "- ReLU\n",
                "- LeakyReLU\n",
                "- Swish\n",
                "\n",
                "Try to train them with optimizers\n",
                "- AdamW\n",
                "- SGD\n",
                "\n",
                "Which one is easier to tune?\n",
                "\n",
                "Try to train these networks on Google Colab for longer\n",
                "Find the best possible batch size (note that the batch sizes usually are selected as powers of 2)\n",
                "- 2\n",
                "- 4\n",
                "- 8\n",
                "- 16\n",
                "- etc.\n",
                "\n",
                "Share your best recepie with everyone and discuss, how did you improve your results"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "collapsed_sections": [],
            "name": "Lesson 5 Digits Recognition Video.ipynb",
            "provenance": [],
            "version": "0.3.2"
        },
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
